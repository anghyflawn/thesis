\chapter{Conceptual foundations of substance-free phonology}
\label{cha:subst-free-phon}

In this chapter I discuss the basic assumptions underlying the framework presented in this thesis. In \cref{sec:modular-enterprise} I give a brief overview of the modular approach to grammar that motivates the conceptual foundation of the theory. \Cref{sec:no-phonetics-modular} focuses on the issue of autonomy, containing a review of the key arguments for the autonomy of phonological representation from substantive realization and for the autonomy of phonological computation from functionally motivated phonetic facts. In \cref{sec:status-interfaces} I sketch a \enquote{rich} model of the interface between phonetics and phonology, rejecting a more deterministic framework relying on transduction. The typological implications of substance\hyp free phonology are the subject of \cref{sec:non--importance}, where I argue that overgeneration is not as fatal a flaw as often assumed, in particular because functionally determined typological tendencies lie outside the purview of the theory of grammar. \Cref{sec:summary} is a brief summary.

\section{The modular enterprise}
\label{sec:modular-enterprise}

At the heart of the present approach is a view of phonology as an \emph{autonomous grammatical module}. In other words, the framework is predicated on the assumption that phonology exists as a separate component of grammar, crucially possessing domain\hyp specific representational and computation systems that are, in principle, independent of the representational and computational systems operating in areas such as (say) morphosyntax and phonetics. Under this conception of phonology, it is substance\hyp free almost by definition: according to the classic modular approach \citep{fodor83:_modul}, the definition of a module includes characteristics such as \emph{information encapsulation} and \emph{domain specificity}. If phonology is a module, then the alphabet of phonological symbols and the types of operations on these symbols are ontologically independent of considerations such as ease of perception and production.

The substance\hyp free approach takes this idea of autonomy and modularity seriously, resting on the assumption that phonology does operate independently of external considerations and could, in principle, allow for the existence of certain systems that are highly implausible when the externalities are taken into account. This assumption comes into conflict with a major result of phonological research from the last century, which is that a very large part of sound patterns attested in human language can be explained as a consequence of pressures exerted by these extraphonological factors. In the substance\hyp free approach, this remarkable fit between functional pressures and attested patterns has to be explained in ontogenetic terms, \ie as the result of the fact that the patterns of attestation in synchronic systems are to a large extent shaped by the history of these systems. This is because language change is strongly affected by the biases acting upon the \enquote{language acquisition device}, which may include both linguistic factors, \ie \posscite{hauser02:_facul_languag} \enquote{faculty of language in the narrow sense}, and extralinguistic biases, such as those due to human anatomy or the general characteristics of the human auditory system \citep[\egm][]{ohala1981}.

This approach stands in contradistinction to other trends in phonological research, which have tried to integrate the phonological system with the external biases, either by shifting much of the explanatory burden traditionally associated with the phonological module to more explicitly functional components such as language change \citep{blevins,blevins06:_evolut_phonol} or by including external biases \emph{into} the phonology \citep[\egm][]{hayes04:_phonet}. Another respect in which the substance\hyp free approach goes against many recent trends is the freedom with which typologically implausible grammars are said to be allowed by the phonological grammar, albeit excluded due to factors such as diachronic filtering: contrast the approach, widespread in work on Optimality Theory, which presupposes that unattested (or \enquote{implausible}) patterns should be excluded by some feature of the grammar (normally the constraint set \textsc{Con} is argued to be set up in a way that ensures all undesirable sets of mappings are harmonically bounded).

In this thesis I defend an approach that takes the modularity of phonology quite seriously, similarly to recent work by authors such as \citet{reiss07:_modul,scheer10:_guide_morph,bermudez-oterong}. Specifically, I suggest that phonology is defined as a module that effects \emph{categorical computation} over \emph{phonological features}, which are units of \emph{lexical contrast}. In this respect, I follow the main tenet of the Contrastivist Hypothesis as it was expressed in structuralist phonology \citep[\egm][]{Tru39,mart55,hjelmslev75:_resum} and recently revived in the \enquote{Toronto School} approach to contrastive specification \citep[\egm][]{torontoschool,dresher-hier,dresher09,currie07}. However, I recognize \emph{features} rather than phonemes as true primitives. Before we turn to a discussion of the issue of contrast, the modular approach \emph{per se} deserves more consideration.

\citet{fodor83:_modul} proposes the following set of characteristics of modules of the human mind (although note that not all of these \emph{define} modularity, \cf \citealt{coltheart99:_modul}):

\begin{enumerate*}
\item Domain\hyp specificity
\item Mandatory operation
\item Limited central accessibility
\item Fast processing
\item Informational encapsulation
\item \enquote{Shallow} outputs
\item Fixed neural architecture
\item Characteristic and specific breakdown patterns
\item Characteristic ontogenetic pace and sequencing
\end{enumerate*}

For various reasons, I will not have much to say about mandatory operation, fast processing, neural architecture, breakdown patterns, or ontogenetic aspects of phonology, although all of these would appear plausibly applicable to this domain. The other properties do deserve some comment (for an overview of issues around the concept of modularity, \citealp[\cf][]{sep-modularity-mind}).

\subsection{Domain-specificity}
\label{sec:domain-specificity}

The modular property of most relevance to the present work is domain\hyp specificity, \ie the requirement that the computation in the module be concerned with objects that are not encountered in other modules\dash in our case, phonological features and sub- and suprasegmental organizing nodes. This requirement immediately disqualifies two types of approaches current in the literature, especially in the OT framework. A domain\hyp specific phonology cannot operate on non\hyp phonological objects, such as formant values \citep[\egm][]{flemming1995} or morphological indices \citep[\egm][]{pater00:_non_englis,pater09:_morph}\dash although it can operate on phonological objects that are the result of interface translation (see \cref{sec:doma-spec-once} below).

Since phonological objects cannot be phonetic, there is no \emph{logical} requirement for features to be defined in phonetic terms, although such definitions do help explain the cross\hyp linguistically frequent near\hyp isomorphism between features as they emerge from phonological analysis (\enquote{natural classes}, although \cf \citealt{mielke-diss} for a critical discussion of this notion) and certain phonetic properties. It can of course be stipulated that, say, the feature [$+$high] be defined to correspond to a high concentration of energy in the region of about 200--400~Hz, or to a high position of the tongue body, but logically such statements are not necessary.

Insufficient domain\hyp specificity is at the heart of \posscite{foley77:_found} attack on early generative phonology as \enquote{transformational phonetics}. \citet{foley77:_found} defends the idea of an autonomous phonology, and views the entanglement between the description and analysis of alternations and the description of the phonetic realization of distinctive units as a category mistake. Instead, he proposes that phonology operates on units defined in entirely non\hyp phonetic terms, specifically using a scale of \enquote{strength}, with these units being converted to more familiar phonetic entities at a later, non\hyp phonological stage of the computation. Although one need not agree with \posscite{foley77:_found} proposal to put the concept of \enquote{strength} at the centre of phonology,\footnote{For a historical review of the concept, see \citet{honeybone08:_lenit}.} the main insight is sound: if phonology is to exist as a module, it has to have an independently defined alphabet of symbols on which the computation operates.

A similar concern underlies the approach to phonological architecture espoused by \citet{reiss07:_modul,hale-kissock-reiss,hale-reiss2008}. They argue that any description of the phonological module of the language faculty should include a description of the phonological alphabet, which they suggest to be sensitive to the presence of certain perceptible cues (such as formant values or transitions, periodicity, durational properties etc.) but insensitive to others (\eg the use of real\hyp world objects such as bananas to perform communicative acts). Although these authors use this premise to reach conclusions that are very different from the approach proposed in this thesis, they are surely correct that any phonological analysis must include a description of a universe of discourse which is specific to phonology and in principle independent of extraphonological considerations (\cf also \citealt{blaho-diss,samuels11:_phonol}).

To conclude, a truly modular approach to phonology must recognize that phonology only operates on phonological entities, and that these entities are in principle defined without reference to phonetics, morphology, and other grammatical domains. A similar consideration applies with respect to the computation, as I discuss in the next section.

\subsection{Encapsulation and inaccessibility}
\label{sec:encaps-impen}

The properties of encapsulation and inaccessibility refer to the flow of information between modules. \emph{Encapsulation} is a property of systems that cannot access information stored in other modules: they can only refer to information contained in the input to the module and to module\hyp internal information. Thus, for instance, a phonological module that is encapsulated with respect to, say, syntax, should not be able to access syntax\hyp internal facts about linguistic objects, \ie\ (at the very least) facts that are obscured in the output of syntax (\eg whether a feature value has been obtained by a syntactic object during the computation or came associated with the item in the lexicon). Similarly, phonology\hyp internal information is not necessarily accessible to other modules, as evidenced by the frequently\hyp cited principle of \enquote{phonology\hyp free syntax} \citep{zwicky69:_phonol,zwicky86:_princ_phonol_free_syntax,miller97:_princ_phonol_free_syntax}, which essentially states that syntax is encapsulated with respect to phonology.

It must be noted that encapsulation has been claimed to not be an indispensable property of modules, in that a module can be encapsulated with respect to some modules but not to others \citep[\cfm][]{prinz06:_is}. Thus, it appears reasonably clear that the speech perception module is encapsulated with respect to, say, conscious beliefs (\ie it is not possible to make a conscious decision to perceive a \ipa{[t]} as a \ipa{[w]}). On the other hand, speech perception can be influenced by input from modules other than hearing, as in the case of sign languages or of the McGurk effect \citep{mcgurk76:_hearin}, although this could simply be a sign that the perception mechanism is multimodal in nature and not restricted to the aural mode of transmission \citep{sep-modularity-mind}.

The upshot of this discussion is that a modular phonology should be expected to operate without reference to information available in other modules, which, importantly, includes phonetics. This means that phonological processes cannot be motivated solely by reference to substantive considerations that do not belong in the phonology proper. A modular approach to phonology is thus incompatible with approaches that seek the \emph{proximate} causes of phonological behaviour in extraphonological domains, such as ease of perception: for instance, it should not be possible to say that \enquote{non\hyp peripheral vowels tend to be disallowed in non\hyp prominent positions [a statement about a phonological phenomenon] because they are more difficult to perceive than peripheral vowels [a statement about the perceptual system]}\dash although it is not at all implausible that such factors will play a rôle in the synchronic system by shaping them over time: they can be ultimate causes, but not proximate ones. This implication is treated in more detail in the next section.

\section{No phonetics in (modular) phonology}
\label{sec:no-phonetics-modular}

The most important theoretical foundation of the present thesis is the assumption of the \emph{autonomy of phonology}. In the modular approach, phonology must possess its own alphabet (\ie phonological representation) and its own computation (here formalized in terms of Optimality Theory), which are \emph{in principle} independent of considerations related to substance. There are two aspects of the substance\hyp free principle:

\begin{itemize}
\item Substance\hyp free representations: the elements of the phonological alphabet are organized without any reference to their physical realization;
\item Substance\hyp free computation: phonological computation makes no reference to factors that are not expressible in phonological terms.
\end{itemize}

In this section I provide an overview of these two aspects.

\subsection{The autonomy of representations}
\label{sec:auton-repr}

At a very basic level, the autonomy of representation means that the phonological alphabet is entirely abstract, with no reference whatsoever to phonetics. The physical realization of phonological units is not the concern of the \emph{phonology}, but rather a matter of the interface (see below \cref{sec:status-interfaces} for more discussion). The purpose of phonology is to match input strings provided by the lexical items to output strings which can be interpreted by the interface (in production mode) and perform the opposite operation (match output strings after interpretation by the interface to input strings); \cf \citet{keating88:_under,moren-foa}. There is no \emph{logical} requirement for these strings to be formulated in a language that makes any reference to non\hyp phonological entities, and, in fact, given the constitutive rôle of domain\hyp specificity for the definition of modules, we do not expect any such reference. Indeed some authors \citep[\egm][]{burton-roberts00:_where} have pointed out that phonology appears to deal with substance, even though \emph{a priori} it should not, if it is part of specifically linguistic competence, and consequently argued for the exclusion of phonology from the \enquote{core} linguistic component \citep[\cf also][]{samuels11:_phonol}. Here, I agree with the latter but not the former premise: phonology is linguistic, but it does not deal with substance.

Thus, in a modular architecture of grammar, it is incumbent on the proponent of a more phonetically oriented approach to representations to show that phonology operates on symbols defined in phonetic terms. Traditionally (\ie since at least \citealt{jfh}), the argument made to this effect is essentially typological (inductive) rather than principled (deductive); I consider it in more detail below in \cref{sec:non--importance}. In this section I briefly present some considerations that might lead us to reject the universality of the phonology\endash phonetics mapping as a working principle.

\subsubsection{Cross-linguistic phonetic variation}
\label{sec:cross-ling-vari}

The broad diversity in the phonetic realization of what appear to be \enquote{the same} phonological representations (which, in practice, usually means that the two segments are transcribed using the same IPA symbol) is by now an established fact \citep{ladefoged84}. The variation ranges from cases such as \enquote{\ipa{[r]}}, which covers an extreme diversity of sounds cross\hyp linguistically, to less systematic differences, such as the relatively large degree of fronting allowed by for \ipa{[u]} in Scottish Gaelic \citep{ladefogedetal-scg} or the differences in the degree of variation permitted in the realization of \ipa{[i]} in languages with small vowel inventories, from relatively large as predicted by dispersion theorists \citep[\egm][]{liljencrants72:_numer_simul_vowel_qualit_system,flemming1995} to quite small, as found in Amis by \citet{maddieson95:_amis}.

The question at stake here is whether this variation is a phonological fact. It appears reasonable that this variation is not a purely mechanic matter that stands outside cognitive control: it should be reflected in our model of the human mind and the human capacity for language. However, whether these facts should be \emph{phonological} is another question altogether.

A common assumption is that phonology covers all non\hyp trivial (\ie non\hyp mechanical) aspects of human behaviour in the domain of speech sounds (and gestures): for one discussion in these terms, see \citet{hammarberg76}, but also \citet{pierrehumbert00:_concep,pierrehumbert02:_word}. However, I would suggest that defining phonology (or indeed any component of the human linguistic competence) in terms of the \emph{behaviour} it is \enquote{responsible} for is a category error, at least if we accept the generative enterprise. Phonology is computation over phonological symbols; whether other components of grammar also happen to produce cognitively controlled phenomena that look similar to phonological ones is not a concern \emph{in} the phonology. In this sense, even if these language\hyp specific phonetic realizations are not purely mechanical \citep{keating90:_phonet,pierrehumbert90:_phonol,phon-knowledge,hale-kissock-reiss}, it is perfectly plausible to locate them outside the phonology.

\citet{hale-kissock-reiss,hale-reiss2008} express a similar insight by introducing a distinction between \enquote{variation} (cross\hyp linguistic differences expressed in terms of phonological symbols) and \enquote{microvariation} (differences introduced \textquote[p.~650]{either by the transduction process, individual physical properties, or external physical events}), although as discussed below in \cref{sec:two-appr-interf} their approach to transduction leaves phonology with a much wider remit than proposed in the present thesis.

Expanding the phonology to account for all cognitively controlled aspects of human behaviour related to sounds has a number of undesirable consequences. Most importantly, it loses sight of the essential difference in kind between symbolic manipulation of lexically contrastive elements (which by necessity differ from language to language) and language\hyp specific phonetic interpretation of these symbols. This thesis can be taken as an extensive argument for the validity of the view which recognizes the existence of a sharp divide, since it shows that this modular approach achieves better descriptive and empirical adequacy (for specific discussion that takes into account concrete proposals with respect to Welsh and Breton, see below \cref{sec:recons-surf-undersp}). For other discussions of the advantages of a modular approach, \cf also \citet{van_oostendorp_coe,bermudez-diachr,bermudez-oterong}.

\subsubsection{Emergent features}
\label{sec:emergent-features}

Substance\hyp free phonology is also able to incorporate recent results related to the emergence of phonological features. The standard position in generative phonology (\citealp{spe}, but also \citealp{jfh}) is that there is a small universal set of features and that all segments are specified, at least on the surface, for all of these features. Weaker versions of this thesis, which allow some underspecification whether in underlying or surface form \citep[\egm][]{kiparsky85:_some_lexic_phonol,kiparsky95,steriade87:_redun,steriade-hbk,archangeli1988,archangeli-pulleyblank,hale-kissock-reiss,hale-reiss2008}, still tend to assume a small, universal set of features that languages can pick and choose from. The arguments in favour of this position have tended to be either typological (the same types of contrast seem to recur in many languages) or based on learning (having a hard\hyp wired universal set of features makes phonological acquisition much easier).

However, both of these types of arguments have come under attack.\footnote{See \citet{mielke-diss,samuels11:_phonol} for discussion of the issue of whether the arguments presented in the literature are in fact good arguments for \emph{universal}, \emph{innate} features.} On the acquisition side, numerous studies have shown that the formation of phonological categories does not require the presence of \emph{a priori} features, but can be result of iterated learning procedures \citep{boersma98:_funct,boersma03:_learn,boersma08,escudero03:_model_optim_theor_gradual_learn_algor,boer00:_self,boer01,oudeyer05}. On the empirical side, \citet{mielke-diss} presents ample evidence that the segment classes predicted by some sets of universal features commonly encountered in the literature are not a very good fit for the segment classes that are active in the phonology of human languages.

\paragraph{An aside on \citet{mielke-diss}}
\label{sec:an-aside-citetmielke}

It must be noted that although I agree with the general thrust of \posscite{mielke-diss} critique of innate, substance\hyp based phonological features, there are several problems with his method. Specifically, he relies on a methodology that involves a broad comparison of rather superficial facts, and does not require in\hyp depth analysis of individual languages.

The basic method used by \citet{mielke-diss} is to identify phonologically active classes, \ie sets of segments that participate in certain alternations as targets or triggers, and see how they line up with the classes predicted to exist by various featural theories. It turns out (p.~118) that of the 6,077 classes in his database, 1,498 (24.65\%) cannot be characterized by any of the three feature theories he uses for comparison, and the best one (that of \citealt{spe}) is only able to cover 4,313 classes (70.97\%). \citet{mielke-diss} identifies several types of uncharacterizable segment sets:
\begin{itemize}
\item Some classes appear to be genuinely \enquote{crazy}, \eg Evenki \ipa{/v~s~ɡ/} as the targets of nasal assimilation. These constitute important evidence for emergent features: as \citet[§6.1]{mielke-diss} discusses, innate feature theory puts a strict limit on how arbitrary a phonological class can be, essentially predicting the non\hyp existence of \enquote{crazy classes};
\item Another type is phonetically natural classes that happen to be impossible to capture due to the specifics of the particular feature theories \citet{mielke-diss} uses for comparison; the existence of these clearly cannot be used as an argument against innate and\fshyp or substantially defined features, but only as an argument against these feature theories;
\item \enquote{Generalization in two directions}, or \enquote{L-shaped} classes, which appear to involve a diachronic process where a phonologically active class comprises two subclasses which are similar to a certain \enquote{core} class in different respects, without necessarily being highly similar to each other. For instance, in Navajo the set of segments that are labialized before \ipa{[o]} includes \ipa{[t~k~kʼ~x~ɣ]}, \ie all voiceless stops irrespective of place (generalization of the [voiceless stop] aspect of \ipa{[k]}) and dorsals irrespective of manner (generalization of the [dorsal] aspect of \ipa{[k]}).\footnote{Note that \ipa{[ɡ]} is exempt but \ipa{[ɣ]} is not. This is not necessarily a problem if we analyse stops and fricatives as using different sets of laryngeal features, as argued by \citet{rice94:_laryn_athap}.} The crucial point is that this pattern cannot be described by a simple conjunction of features that does not cover other segments: it is quite difficult to express the Navajo generalization by a relatively traditional featural class, because such a class clearly has to allow both coronals (to account for \ipa{[t]}) and, say, voiceless fricatives (to account for \ipa{[x]}) but then some provision has to be made for voiceless coronal fricatives such as \ipa{[s]} and \ipa{[ɬ]}, which are excluded.
\end{itemize}

The last point exemplifies at least two problems with \posscite{mielke-diss} approach. First, he excludes the segments \ipa{[kʷ~xʷ~ɣʷ]} from the class, but it is not obvious that they do not undergo labialization in a vacuous manner. This illustrates the  difficulty of identifying whether a set of segments \enquote{participates} in an alternation without considering the analysis in detail. From a computational perspective, a segment that undergoes some change in its representation is clearly part of the class defined by that change, even if that change is phonetically vacuous. It is not entirely obvious how such cases could be identified using \posscite{mielke-diss} methods.

Secondly, as \citet{mielke-diss} concedes, the problem of the L-shaped classes can be solved in (some versions of) Optimality Theory \citep{flemming05:_deriv}, since it allows multiple constraints to block the appearance of certain segments or the application of certain processes to produce the desired effect: in this case, constraints against the labialization of coronal fricatives could be created by constraint conjunction.\footnote{Note, however, that the architecture of OT requires that the class in this case should be formed by the non\hyp undergoing segments, because the constraint must have something to refer to in order to be active; in other words, the undergoing segments are not those that contain an active feature, but rather those that fail to resist the process. This is not a problem in framework with binary features, because the existence of a constraint against any value of a feature presupposes the existence of that feature, but in a privative approach this requires that, say, in Navaho, it is the coronal fricatives that bear some features for markedness constraints to react to. Again, this is a difficulty for \posscite{mielke-diss} approach which relies on broad comparison, because it makes the precise identification of natural classes more difficult.} Similarly, \enquote{class subtraction} (\ie a situation when a only a non\hyp characterizable subset of a predicted featural class is phonologically active, but adding some other featural class to this subset results in a characterizable class) is trivial to achieve in OT by ranking the markedness constraints against the co\hyp occurrence of relevant features high enough.

\posscite{mielke-diss} answer to these concerns is essentially typological: \blockquote[p.~166][.]{If factorial typology is taken seriously, then classes which are defined with fewer interacting constraints are expected to be more common, and this in turn depends on the feature set which is used to formulate the constraints}. \citet{mielke-diss} suggests that this prediction may not be borne out by his data, which, for him, casts doubt on the adequacy of the OT approach. However, this prediction holds only if the number of interacting constraints is the sole factor influencing the number of attested surface grammars, which, in turn, implies that the ranking of these interacting constraints is entirely random. In \cref{sec:non--importance} I will argue that such arguments are of extremely limited relevance to the nature of human phonological competence.

\paragraph{The need for emergent features and the nature of the evidence}
\label{sec:need-emerg-feat}

The objections given in the previous paragraph are not meant to invalidate \posscite{mielke-diss} convincing argument against innate, substance\hyp based features. My concern is not so much with the conclusion as with the methodology. As \citet{mielke-diss} recognizes, the \enquote{phonologically active classes} gleaned from a list of alternations are important as a source of evidence for the nature of phonological computation, but they are not \emph{the} evidence. In any theory that relies on emergent features, the evidence should come from a detailed consideration of the pattern found in any given language, including an explicit statement of the division of labour (\ie which processes are phonological and which are not), an explicit set of the features required for that language, and a detailed analysis of the phonological evidence with a view to discovering the featural specifications of each particular segment. Only such analysis can show whether a given \enquote{phonological class} is in fact defined in terms of a certain feature or feature set in the language or whether it is an epiphenomenon resulting from the interaction of several unrelated patterns.

The aim of this thesis is to contribute to just such a study. The method chosen here owes a lot to microcomparison, \ie the comparative analysis of a certain phenomenon in a group of closely related varieties. The advantage of microcomparison is that closely related systems are often quite similar due to their common origin, decreasing the possibility of random factors disturbing the differences between the subsystems of interest. For our purposes, however, microcomparison has the disadvantage of concentrating a narrow set of phenomena, whereas an adequate analysis of phonological patterns, as understood in this thesis, requires a holistic approach to the system.

For this reason, in this thesis I present an overall analysis of the phonological systems of two closely related languages, namely Pembrokeshire Welsh and Bothoa Breton, in order to explicate the sources of cross\hyp linguistic variation. Unlike the microcomparison approach, I do not concentrate on a single phenomenon (say, \enquote{vowel reduction}); however, the close relationship between the two languages makes the overall make\hyp up of the system quite comparable, putting the similarities and differences between the two into greater relief. I will defend the position that cross\hyp linguistic variation is due not only to the computation (implemented as differences among languages in terms of constraint ranking) but also to representations, which are language\hyp specific, and thus by necessity (at least conceptually) substance\hyp free, in line with \citet{moren-serbian,moren-foa,uffmann07:_restr,blaho-diss,youssef10:_laryn_buchan_scots} and in contrast to the standard OT position that only constraint ranking is important for cross\hyp linguistic variation (see especially \citealp{uffmann07:_restr} for discussion). In particular, I will show that the differences in the phonological systems of the two languages are best described in terms of features that are not deterministically assigned on the basis of phonetic realizations, but rather reflect the patterns found in the phonology of the languages.

To conclude, I suggest that a framework with language\hyp specific, emergent, substance\hyp free features is superior to one utilizing innate features defined in terms of substance, on the grounds of empirical adequacy. This is because the former, but not the latter, predict the existence of (relatively) \enquote{crazy} phonologically active classes that cannot be described in terms of the phonetically based featural systems proposed in the literature. However, conclusive evidence for such \enquote{crazy classes} cannot come from a broad analysis of trends in featural inventories, such as that undertaken by \citet{mielke-diss}; it requires detailed consideration of specific languages, and it is the aim of this thesis to contribute to this type of study.

\subsubsection{Sign languages}
\label{sec:sign-languages}

Further evidence for the autonomy of representations comes from languages that do not use the aural modality (first and foremost sign languages). As discussed by \citet{hulst93:_units_analy_signs,moren-psm}, if the phonology of spoken and sign languages share the same computational module (call it \enquote{Universal Grammar}) \citep{sandler93:_sign}, then the mapping between phonological representations and phonetic realizations provided by UG cannot be modality\hyp bound (and thus cannot be the \enquote{universal phonetics} of \citealp{spe}). It follows that the mapping between phonology and phonetics is, in principle, language\hyp specific and must be learned, buttressing the emergent\hyp feature hypothesis.

\subsection{The autonomy of phonological motivation}
\label{sec:autonomous-phonology}

The upshot of the discussion in the previous section is that based on first principles and some suggestive data, the modular framework leads us to the hypothesis that the mapping between phonological symbols and their physical realization cannot be universal and innate, but must be language\hyp specific and learned. Similarly, the proximate motivation for phonological phenomena such as alternations cannot be phonetic, but must be domain\hyp specific in terms of the phonology. While I generally use \enquote{substance\hyp free} as a label for this type of framework, a more precise description would probably be \emph{autonomous}: there are aspects of phonological representation that are not determined by the phonetic realization of phonological contrasts. In this section I provide a brief overview of the types of arguments made in defence of this position.

\subsubsection{Against universal phonetics: language\hyp specific representation}
\label{sec:against-univ-phon}

The claim that phonological representations are more or less trivially \enquote{read off} the phonetic substance is a familiar one. Starting from the acoustic feature theory of \citet{jfh} and the \enquote{universal phonetics} of \citet{spe}, phonological computation was assumed to produce as its ultimate output representations of physical events. An often\hyp made corollary was that the mapping from phonology to physical events was simple and universal (\cf the \enquote{transduction} quoted by \citealp{hale-kissock-reiss,hale-reiss2008}). Speaking very roughly, we can identify three principal ways in which this conception was formalized, which are as follows:

\begin{itemize}
\item The SPE tradition, building more or less directly on the set of features proposed by \citet{spe}, or occasionally explicitly conceived as an alternative to that particular formalism, without significant differences with respect to modular organization. This type of framework includes both SPE\hyp style bundles of features (often with definitions biased towards articulation) and autosegmental and geometrical approaches \citep[\egm][]{sagey86,mccarthy88:_featur,clements91:_place,clements-hume1995,halle95:_featur_geomet_featur_spread};
\item The \enquote{realist} tradition, which strives to bring the output of phonology as close to physical events as possible, making it regulate very concrete details of physical implementation, often without regard to issues such as lexical contrast and morphophonological alternations that have traditionally been at the centre of theoretical attention. This tradition has, not surprisingly, been often associated with work in automatic speech processing. Examples include Articulatory Phonology \citep[\egm][]{browgold90,silverman03} and many declarative approaches \citep[\egm][]{ScobbieColemanBird,scobbie1997,coleman98:_phonol,Lodge2003931,lodge07:_timin_icelan,lodge09:_fundam_concep_in_phonol}, as well as recent approaches based on rich\hyp memory models (\citealp{pierrehumbert01:_exemp,pierrehumbert02:_word}, \cf also \citealp{pierrehumbert00:_concep,scobbie07:_inter,scobbie08:_quasi});
\item The element\hyp based tradition \citep[\egm][]{anderson87:_princ_depen_phonol}. Especially in the relatively recent guise of Element Theory \citep{harris94:_englis,harris05:_vowel_reduction,harris06,harris95,backley11:_elemen_theor}, this framework emphasizes that, while phonological elements are in principle abstract (\ie properly phonological) entities, they also have direct acoustic (and, importantly, perceptual) correlates, making it relatively easy to recover element\hyp based phonological representations from the phonetics.
\end{itemize}

Relatively few phonologists pay more than lip service to the abstract, non\hyp substance\hyp bound nature of phonological features. Although structuralist phonology recognized, following Saussure, that the prime factor defining phonological representation was not phonetic (since representations were based on contrast; \cf \citealp{Tru39,hjelmslev43:_omkrin,hjelmslev75:_resum} and see the overview by \citealp{dresher09}), most work in the generative tradition has not embraced truly abstract representation, with a few exceptions such as \citet{foley77:_found}, discussed above, and the recent growth of various \enquote{substance\hyp free} approaches \citep{hale00,hale-reiss2008,hale-kissock-reiss,moren-serbian,moren-foa,blaho-diss,youssef10:_laryn_buchan_scots,samuels11:_phonol}.

In addition, despite the description of Element Theory as substance\hyp bound above, there is much work in that tradition that gives more weight to the phonological (or even morphophonological) patterning of segments rather than their phonetic realization; for recent examples of sophisticated representational argumentation on the basis of phonological alternations, \cf \citet{gussmann07,cyran10:_compl}. Even the textbook treatment by \citet{backley11:_elemen_theor}, which largely relies on \citeauthor{harris94:_englis}' (\citeyear{harris94:_englis}, \emph{et passim}) perceptual theory of elements, contains numerous ambiguous passages such as the following: \blockquote[p.~182][.]{Adding \ipa{|ʔ|} makes no difference to the phonetic shape of laterals [\ldots]. It does makes a difference phonologically, however, as it links \emph{l} to the class of stops} Although the ambivalent behaviour of laterals in terms of (phonological) continuancy is not surprising \citep{mielke05:_ambiv}, this example shows that Element Theory, with its insistence on the recoverability of phonological representation from phonetics, arguably cannot avoid what is essentially substance\hyp free argumentation that builds on exclusively phonological facts.

The main premise of this thesis, along with other recent work in the vein of substance\hyp free phonology \citep{moren-serbian,moren-foa,blaho-diss,youssef10:_laryn_buchan_scots,uffmann10,iosaded:_final_italy,iosad10:_motiv}, is that \emph{phonological behaviour} is the key to phonological representations. The insight is by no means new, and there have been several types of evidence adduced in its favour, which I briefly list here.

\subsubsection{Contrast}
\label{sec:contrast}

The constitutive rôle of contrast in phonological specification has been recognized in structuralist approaches inspired by \citet{saussure16:_cours}, as in \citet{Tru39,mart55,jakobson56:_fundam,hjelmslev43:_omkrin,hjelmslev75:_resum}. Thus, for \citet{Tru39}, phonemes are defined by their distinctive function; however, \enquote{distinctive function can [\ldots] only be ascribed to a sound property inasmuch as it is opposed to another sound property}.\footnote{\foreigntextquote{german}[\citealp{Tru39}, p.~30][\ldots]{Distinktive Funktion kann [\ldots] einer Lauteigenschaft nur insofern zukommen, als sie einer anderen Lauteigenschaft gegenübergestellt wird}} Most importantly for structuralists, phonological representation was \emph{language\hyp specific} almost by definition, since the phonological content of any element could only be established on the basis of its relationships to other elements of the same system, and not to \emph{a priori} considerations such as its pronunciation. Similar considerations underlie the resurgence of underspecification theory in the 1980s \citep{archangeli1988,steriade87:_redun,steriade-hbk}, especially Modified Contrastive Specification \citep{torontoschool,dresher-hier,dresher09,currie07}, where the primary function of phonological features is to implement contrast in the lexicon. A strong form of the \emph{Contrastivist Hypothesis} is formulated by \citet[p.~20]{currie07}: \blockquote{The phonological component of a language L operates only on those features which are necessary to distinguish the phonemes of L from one another.}

As discussed in \cref{cha:categ-contr-mark}, the present thesis proposes one possible approach to the Contrastivist Hypothesis, in a version that is fairly strong in representational terms, but allows more leeway to the computation. The motivation behind strong contrastivist approaches is essentially parsimony, understood as the avoidance of elements the existence of which cannot be independently demonstrated. In this sense, lexical contrast is an unavoidable null hypothesis, since it is established by the very existence of the lexicon. The question is whether phonology should or can add material that is \emph{not} necessary for lexical contrast on the way from input to output. In a substance\hyp free theory, there is no condition for the output to be trivially interpretable phonetically. In the absence of other compelling evidence for the addition of material other than that needed for contrast, the null hypothesis therefore has to be that the contrastivist hypothesis is correct, at least as far as (subsegmental) features go. Throughout this thesis, I argue that there is no compelling reason for this null hypothesis, or at least a minimally refined version of it, to be rejected.

\subsubsection{Markedness}
\label{sec:markedness}

Ever since \citet{Tru39} it has been recognized that the relationships between (some) phonological elements are asymmetrical, in that some phonemes are distinguished from others by the presence versus absence of some elements. Starting out as a purely formal notion defined by the presence of the \enquote{mark} (\textgerman{\emph{Merkmal}}), markedness quickly accrued many additional connotations as a property used to describe various aspects of human language competence (for recent overviews, see \citealp{haspelmath06:_again,rice07:_marked,hume11:_marked}).

I will discuss the relevant notions of markedness in more detail below (\cref{sec:mark-hier-contr}). The importance of markedness for the autonomy of phonology lies in the question of whether markedness\hyp related phonological behaviour is directly tied to phonetic substance. Positive answers to this question in formal phonology have tended to dedicate a special markedness \enquote{submodule} that ensures that phonological elements pronounced as certain sounds in certain contexts behave in a particular way, as in \citet[ch.~9]{spe} or \citet{calabrese-book} and in work on underspecification theory with redundancy rules \citep[\egm][]{archangeli-pulleyblank}. (A more careful distinction is made by \citealt{delacy2002,lacy04:_marked_optim_theor,delacy2006}, who ascribed markedness\hyp related behaviour as such to structural factors but still includes the close relationship to substance as an additional postulate of the theory.) Given that such markedness statements have tended to be of a type that allows functional and\fshyp or diachronic explanations, it has also been proposed that they merely recapitulate these explanations and are thus unnecessary \citep[\egm][]{ohala1981,hayes04:_phonet,blevins}, or that markedness is in some sense emergent from such factors and thus not very interesting for phonological theory.

However, it has also been demonstrated that the markedness\hyp related behaviour of what appear to be \enquote{identical} sounds is both language\hyp specific and not necessarily functional. The first line of attack has been particularly prominent in work by \citet{rice92,rice94:_laryn_athap,rice96:_defaul_variab,rice03:_featur,rice07:_marked,rice11:_what}, who shows that standard markedness diagnostics may designate most types of segments as \enquote{marked} or \enquote{unmarked}, with no apparent functional motivation; the conclusion is that the mapping between markedness classes and substance is driven by phonology\hyp internal (\ie functionally arbitrary) considerations, which is exactly what we expect under a substance\hyp free approach. A second approach, exemplified \eg by \citet[\emph{et passim}]{hume04:_decon}, derives markedness\hyp related behaviour from frequency. Whether or not that is true, it still implies that the mapping is \emph{learned}, and thus potentially not universal but rather language\hyp specific, which allows us to excise markedness statements à~la \citet[ch.~9]{spe} from the universal part of phonological grammar. This is exactly what a substance\hyp free approach requires.

\subsubsection{Rule scattering}
\label{sec:rule-scattering}

The autonomy of phonology is also demonstrated by the existence of a situation where several grammatical modules possess mechanisms that give rise to very similar sound patterns, with the distinction between phonetics and phonology usually treated as a distinction between continuous and discrete (categorical) patterns (although see \cref{sec:relev-categ-distr} below for more on this issue). An ontological distinction between superficially similar processes in different languages has been repeatedly demonstrated in domains such as vowel harmony \vs vowel\hyp to\hyp vowel coarticulation \citep[\egm][]{przezdziecki05:_vowel_yorub}, vowel reduction \citep{barnesbook,kingston07}, consonant palatalization \citep{zsiga95:_americ_englis,zsiga00:_phonet}, and tone spreading \vs peak delay \citep{myers-phonoknowledge}.

An important special case of this situation is found when \emph{the same language} actually possesses a version of some sound pattern in several components of grammar, dubbed \enquote{rule scattering} by \citet{bermudez-otero10:_curren_englis}, following  \citet{robinson76:_scatt_rule_swiss_german}.\footnote{\citet{cohn98} calls these situations \enquote{phonetic doublets}.} Examples include vowel reduction in Russian \citep{barnesbook,barnes2007,iosad10:_motiv} and Bothoa Breton (\cref{sec:stress-relat-altern}), palatalization in English \citep{zsiga95:_americ_englis}, and gemination in Hungarian \citep{pycha09:_lengt,pycha10}; \cf also \citet{bermudez-otero10:_curren_englis} for further examples from English. The existence of rule scattering is an important argument for a phonology that is separate from the phonetics, establishing that the two can indeed produce very different outcomes.

\subsubsection{Crazy rules}
\label{sec:crazy-rules}

A related argument for the autonomy of phonology from functional factors is often adduced on the basis of the existence of so\hyp called \enquote{crazy rules} \citep{bach72:_how}, \ie phonological alternations that have no obvious synchronic rationale but represent the accrual of successive historical changes. \citet{anderson81:_why} makes this argument in the context of the naturalness controversy, arguing that an abstract phonological computation is necessary to represent the knowledge of the relevant facts. Similar arguments are also adduced in the study of the life cycle of sound patterns, with a distinction between \enquote{natural}, phonetically motivated and phonetically driven processes and phonological processes that are the result of their phonologization \citep[\egm][]{hyman76:_phonol,kiparsky95,mcmahon00:_lexic_phonol_englis,janda,barnesbook}.

This argument has come under fire from functionalist approaches. One prominent example is Evolutionary Phonology \citep{blevins,blevins06:_evolut_phonol}, which does away with synchronic abstract computation by declaring it a mere duplicate of the historical explanation: in other words, if a historical account is available for the existence or otherwise of a certain sound pattern, no synchronic devices are necessary for this purpose. Crucially, however, this view presupposes that there are no abstract biases in speakers' knowledge of language, meaning that they can basically learn any pattern present in the ambient data, as long as it has been produced by a certain sequence of changes; the factors ensuring the non\hyp attestation of certain patterns are purely functional (\citeauthor{blevins}' CCC model of sound change). The position that humans can learn basically anything using domain\hyp general mechanisms as long as there is sufficient ambient data is also buttressed by the burgeoning study of statistical learning (see \eg the papers in \citealt{bod03:_probab}). However, as emphasized by authors such as \citet[\eg][]{yang02:_knowl,yang04:_univer_gramm}, statistical learning still relies on a well\hyp defined problem domain: as \citet[p.~452]{yang04:_univer_gramm} puts it, \textquote{[a]lthough infants seem to keep track of statistical information, any conclusion drawn from such findings must presuppose that children know \emph{what kind} of statistical information to keep track of}.\footnote{For a discussion of the computational difficulties with formulating hypotheses for statistical learning (albeit in the context of PAC learning rather than the Bayesian approaches common in linguistic work), see \citet[§7.1]{aaronsonng:_why}, according to whom \textquote{induction \emph{cannot} be merely a matter of seeing enough data and then \enquote{generalizing} from it, because immense computations might be needed to \emph{find} a suitable generalization}. See also the discussion in  \cref{sec:choice-approach} below.} The fact that there may be a historical explanation for a sound pattern does not represent a full explanation of how the speakers represent the knowledge of that sound pattern, and it is a separate question whether there are any independent restrictions on that aspect of phonology.

It would seem that historical plausibility is not the only factor influencing what is a possible phonological system. There are two main arguments adduced against the position that there is nothing specific to phonology in the learning process. One, advocated by \citet{kiparsky08:_univer,hyman08:_univer,lacyng:_synch}, is the non\hyp occurrence of some patterns that we could otherwise expect to exist (or even recur) given their straightforward historical rationale. I would suggest that this argument is not particularly strong: first, because it is an \emph{argumentum e silentio}, second, because in a substance\hyp free theory many of the putative examples are unavailable. For instance, \citet{delacy2006,lacy06:_trans,lacyng:_synch} offer \ipa{[k]}\hyp epenthesis as a potential \enquote{impossible} process and attribute it to a ranking that never makes the feature [dorsal] (or, in more precise terms, [$xxx$Place]) possible in epenthesis; this type of argument is not available in substance\hyp free phonology, because Universal Grammar cannot make reference to a specific feature, and in fact in many languages dorsals would appear to be segments of relatively low markedness in terms of place,  either exhibiting susceptibility to place\hyp changing processes (for examples, see \citealt{rice96:_defaul_variab,rice03:_featur,moren-serbian} and \cref{sec:velar-palatalization} below) or being the outcome of place neutralization \citep[\egm][]{rice07:_marked,ramsammy11:_spanis,ramsammyng:_word_spanis}.

A second, probably stronger argument is found in cases where speakers fail to phonologize phenomena for which the ambient input contains robust statistical evidence, or where their learning appears biased in directions that do not have an obvious functional source. Some examples of the former are found in work by \citet{moreton06:_analy} (although see \citealt{yu11}) and \citet{becker09:_phonol,becker11:_surfeit_stimul}. Similarly \citet{beckerng:_asymm_gener_alter_initial_syllab} show that initial\hyp syllable faithfulness trumps statistical biases in the input.

On the other hand, there is also some evidence that although the learner's acquisition device does have some biases making certain types of patterns unacquirable, these biases do not necessarily have a firm phonetic grounding. Although it has often been claimed that functionally grounded rules are easier to acquire \citep[\egm][]{demuth95:_marked,jusczyk02:_how_englis_learn_infan_respon}, the reverse result has also been obtained, for instance by \citet{seidl05}. Thus, while statistical learning is not completely unconstrained, it is also not necessarily the case that phonological learning is grounded in functional considerations.

The bottom line is that the existence of functionally unmotivated sound patterns (\enquote{crazy rules}) necessitates a mechanism of learning and representation that is distinct from the functional biases active in acquisition, production and perception. That mechanism can be either domain\hyp general (\eg general learning capabilities, often assumed to be statistically based) or domain\hyp specific (essentially, an autonomous phonology). The question of whether domain\hyp general mechanisms are sufficient to achieve the requisite knowledge is an open one, but I suggest there is significant evidence that some domain\hyp specific component of phonological knowledge is in fact necessary, which again leads us to an autonomous phonology.\footnote{Note that this endorsement of domain\hyp specific learning is not necessarily at odds with the results regarding learning of categories in phonological acquisition discussed in \cref{sec:emergent-features}. I advocate a framework where a specific phonological component is present but \emph{minimalist}. Emergent categoricity shows that learners can extract categories from the signal, without any bootstrapping from a universal phonetics\endash phonology mapping, but it does not mean that there are no domain\hyp specific ways of representing and manipulating these categories once they have been acquired.}

\subsubsection{Diachrony}
\label{sec:diachrony}

A last argument, on which I will only touch briefly, concerns diachrony. Although diachronic change \emph{per se} is usually (and broadly correctly) not assumed to be a part of synchronic linguistic competence \citep[\cf especially][]{hale03:_neogr,hale07:_histor}, there can be no doubt that change is in one way or another related to the functioning of the synchronic system. For our purposes, at least two types of diachronic arguments are available to show the need for an autonomous phonology.

One such argument is the existence of the life cycle of sound patterns already referred to above. First, there are numerous examples of phonetic patterns changing in nature as they enter the phonology, a process traditionally known as phonologization \citep[\egm][]{hyman76:_phonol,barnesbook,kingston07}, \cf also \posscite{janda} \enquote{dephoneticization}. The difference between phonological and phonetic patterns established the existence of two different domains of grammar. A second argument from the existence of the life cycle concerns the important differences between processes affiliated to different submodules in the phonology, which have been emphasized in the Lexical Phonology tradition, \eg by \citet{kiparsky95,mcmahon00:_lexic_phonol_englis,kaisse11:_lexic_phonol} and especially \citet[\eg][]{bermudez-diachr,bermudez-otero10:_curren_englis,bermudez-oterong}. The stratal organization of grammar makes a number of important predictions (see \cref{sec:strat-aspects-comp} for more discussion of the stratal model), which are non\hyp trivially related to diachronic factors and also appear not to be reproducible in a non\hyp stipulative way in non\hyp modular theories (see \citealt{bermudez-oterong} for an extended exposition).

Another diachronic argument for an autonomous phonology involves the existence of phonological change without (large\hyp scale) phonetic change. While much work has emphasized the rôle of performance and of perception and production biases in sound change \citep[\egm][]{ohala1981,blevins}, it has also been recognized that change can also consist in the reinterpretation of some ambient data in terms of a different grammar than that by which those data were produced\dash this is \posscite{andersen} \enquote{abductive} change, and a similar mechanism underlies the proposals of \citet{hale03:_neogr,hale07:_histor} and \posscite[']{blevins} \textsc{chance}. The existence of such changes crucially presupposes that the mapping between phonetic and phonological form is not trivial, and thus that phonological form cannot be recovered from the signal. The mechanism for these changes must involve some device which mediates between different surface forms by ascribing them to an abstract representation, which, in turn, can have its own autonomous properties. A recent example of such thinking is provided by \citet{buckley09:_phonet_gallo_roman}. He describes a process whereby velars became palatalized before the vowel \ipa{[a]} in Gallo\hyp Romance dialects, which does not seem to have an immediately obvious phonetic motivation. \citet{buckley09:_phonet_gallo_roman} argues that the palatalization spread from contexts where \ipa{[a]} was found in an open syllable and underwent allophonic fronting, providing the phonetic conditioning for palatalization, to closed\hyp syllable contexts where the \ipa{[a]} was never fronted. He suggests that the speakers acquired a generalization whereby members of the category \enquote{[velar]} could never precede members of the category \enquote{\ipa{[a]}}, even if there was no phonetic motivation for it in the case of closed\hyp syllable \ipa{[a]}: the crucial point here is that speakers must have been aware of the fact that \phonint{æ}-like tokens and \phonint{a}-like tokens belonged to a single category \ipa{/α/}. Again, this can only happen if there is an autonomous phonological representation which is not trivially recoverable from the signal.

\subsection{Conclusion on autonomy}
\label{sec:conclusion-autonomy}

In this section I have summarized a number of arguments which demonstrate the need for a phonological representation that is both distinct in kind from a phonetic representation \citep[\cfm][]{keating90:_phonet,phon-knowledge} and not trivially recoverable from the signal. The two major points are the autonomy of phonological representation from phonetic reality and the existence of phonology\hyp specific representational and computational principles.

The first point has major consequences for phonological analysis. If phonological representation cannot be taken at face value, any analysis must first make explicit the procedure used for the discovery of these representations. In this thesis I defend a minimalist approach that rejects a relatively strong conception of Universal Grammar with a narrowly defined set of representational primitives, and subscribe to a more emergentist approach whereby phonological representations are learned on the basis of ambient data.

The second point is that the functioning of phonology cannot entirely be derived from domain\hyp general or functionally driven mechanisms. Most of the evidence given so far has concentrated on the existence of phonological categories. A significant amount of work exists that recognizes the existence of categories alongside more finely grained \enquote{gradient} phenomena \citep[\cfm][]{pierrehumbert00:_concep}, although sometimes it is argued that categorical behaviour can emerge from bottom\hyp up interactions \citep[\egm][]{wedel}. I would suggest that the potential of categorical phonology has been far from exhausted, and that an explicit theory of how phonological categories may interact once they are in place still remains desirable (see also \citealt{cohn06:_is,cohn10:_labor_phonol,cohn11:_featur}). Only offering such a theory may put us in a position to compare the formalist, modular approach to frameworks seeking a non\hyp modular integration between different types of the knowledge of sound patterns.

\section{The status of the interfaces}
\label{sec:status-interfaces}

If we accept a modular view of the language faculty, we are faced with a dilemma regarding the type of interaction between modules. Barring a complete disavowal of the modular perspective, such as that often encountered in approaches based on massively parallel architectures \citep[\egm][]{rumelhart86:_paral,smolensky06:_harmon_mind},\footnote{See also \citet{scheer10:_guide_morph,scheer11:_issues} for a modularist critique of parallel approaches to phonology.} there are two possible positions, which I shall call the \enquote{poor} versus the \enquote{rich} interface model.

\subsection{Two approaches to the interface}
\label{sec:two-appr-interf}

The \enquote{poor} interface model is more akin to \posscite{fodor83:_modul} original conception, where the translation between the symbolic alphabets specific to each module is undertaken by the simple and deterministic mechanism of \emph{transduction} \citep[\egm][]{pylyshyn84:_comput}. In phonological scholarship, this position has been taken most explicitly by \citet{hale-kissock-reiss,reiss07:_modul,hale-reiss2008}, who argue that \textquote[\citealp{hale-kissock-reiss}, p.~647]{these two transducers [perception~$\rightarrow$ phonology and phonology~$\rightarrow$ articulation] are innate and invariant\dash they are identical in all humans (barring some specific neurological impairment) and do not change over time or experience (\ie, they do not \enquote{learn})}. In this approach, the roots of which go back to at least \citet{jfh} and \citet{spe}, the mapping between phonological units such as features and articulatory and\fshyp or perceptual entities is relatively simple and highly consistent cross\hyp linguistically (although \citealt{hale-kissock-reiss} do have a place for language\hyp specific mechanisms in the mapping from signal to phonology). This approach does not exclude a substance\hyp free view of phonological computation in the sense that computation may still proceed without reference to extraphonological considerations, as proposed by authors such as \citet{hale00,hale00:_phonol,hale-reiss2008,hale-kissock-reiss,reiss03:_quant,reiss07:_modul} and \citet{samuels11:_phonol}, but it does significantly reduce the amount of cross\hyp linguistic variation in sound patterns that is due to factors other than phonology, by drastically simplifying the interface.

A contrasting view, expressed perhaps most prominently by \citet{jackendoff87:_consc,jackendoff92:_languag,jackendoff97,jackendoff00:_fodor,jackendoff07:_found},\footnote{For similar approaches in cognitive science, \cf \citet{bever92} and especially \citet{coltheart99:_modul}.} sees both \enquote{modules} and \enquote{interfaces} as essentially similar entities, without a significant difference in complexity. \citet{jackendoff07:_found} calls the different types \enquote{integrative} and \enquote{interface} modules: the difference is that the former take objects of identical types as their inputs and outputs, while the latter effect a translation between different types of objects. In phonological terms, this means that the interface between phonetics and phonology differs from both phonetics and phonology in that it takes as its input phonological representations and produces as its output phonetic entities, for instance gestural scores à~la \citet{browgold90,silverman,hale-reiss2008} (in production mode), or vice versa, taking some perceptual representations and translating it into a surface\hyp phonological representation (in perception mode).\footnote{Of course production and perception can be two different interface modules; this is immaterial here. In  this thesis I focus mostly (although not exclusively) on the production direction of the phonetics\endash phonology interface.} In other respects, it behaves like any other module in the grammar, in particular it is not necessarily innate, but may be learned, with the consequence that there is no expectation of universality. In other words, under the \enquote{rich} interface approach it is only to be expected that \enquote{similar} phonological representations should demonstrate some language\hyp specific variation in their phonetic realization.

In this thesis I subscribe to a version of the rich interface model. I assume that the translation between phonological and non\hyp phonological representations is not trivial and, in particular, that it is not cross\hyp linguistically consistent. Importantly, however, it still remains a module, with the implications that modularity has for encapsulation. Specifically, the phonetics\hyp phonology interface has no access to information that is not somehow accessible via the output of the phonological module, such as underlying forms of morphemes, contrasts obscured in the course of phonological computation, and the morphological affiliation of phonological objects.

\subsection{Domain\hyp specificity once again}
\label{sec:doma-spec-once}

The essence of domain\hyp specificity is that each module only computes symbols of a certain type, and cannot access symbols belonging to other domains. Its importance lies in the fact that, given the above conception of the modular architecture, an integrative module is essentially defined by the type of elements that are well\hyp formed for the purposes of the module\hyp specific computation; simplifying somewhat, we could say that the definition of phonology is \enquote{the module that takes strings of phonological objects (such as features and suprasegmental structure, which should then be defined independently) and outputs strings of phonological objects}. However, such a strict interpretation of modularity raises some important issues, which are discussed in this section.

\subsubsection{Domain-specificity and interface interpretability}
\label{sec:doma-spec-interf}

A consequence of domain\hyp specificity is that certain types of interactions between modules are prohibited: for instance, phonology cannot manipulate syntactic objects such as constituents. However, some information can be transmitted across module boundaries by the interface; in phonology, this line has been taken most commonly in prosody, where prosodic structure is built with reference to syntactic boundaries but phonological processes proper (\eg intonation construction) only operate on these boundaries (\citealp[\eg][]{selkirk,nspvgl,truckenbrodt,seidl} and, in a different approach, \citealt{scheer10:_guide_morph}) rather than directly on boundaries of syntactic constituents \citep[\egm][]{kaisse85:_connec,odden90:_syntax_kimat}.

However, the treatment of category- or morpheme\hyp specific effects in word\hyp level phonology has been more controversial. The existence of category\hyp specific effects (\eg phonological differences between nouns and verbs) has been often recognized, which seemingly necessitates analyses where the phonology has to make reference to the morphological affiliation of its symbols, in apparent violation of modularity. However, this can be remedied by assuming that the morphosyntax\endash phonology interface translates this morphological affiliation into (arbitrary) \emph{phonological} objects. This solution has been especially frequently adopted in an OT context in the guise of lexical indexation \citep[\egm][]{fukazawa97:_japan,itomester-strata,pater00:_non_englis,pater09:_morph,gouskova07:_tonkaw,gouskova11:_unexc,jurgec10:_disjun_lexic_strat} or cophonologies \citep[\egm][]{orgun96:_sign,orgun99:_sign,orgun02:_recon,inkelas98,inkelas05:_redup,inkelas07:_is,inkelasng}. Another solution is the theory of Coloured Containment \citep[\egm][]{van_oostendorp_coe}, where phonological computation does not see morphosyntactic labels \emph{per se} but still has access to the morphology\hyp derived notion of \emph{colour}.

I do not treat these issues in great detail in this thesis. However, it must be pointed out that in a modular theory all morphologically derived markers must still be \emph{phonological} objects, by the definition of domain\hyp specificity. At the same time this type of marking, as proposed in the literature, tends to be immune to manipulation by the phonology: it is usually assumed that the phonological computation cannot alter either the affiliation of a morpheme to a lexical stratum\footnote{This case must crucially be distinguished from cases where a morpheme's stratal affiliation stays intact but fails to influence the phonological computation, \ie the \enquote{wrong} phonological rules apply, as in \citet{jurgec10:_disjun_lexic_strat}.} or the morphological affiliation (or \enquote{colour}) of a phonological symbol (the latter is known in the OT literature as Consistency of Exponence). In principle, if the diacritic morphologically\hyp derived marking of phonological elements is indeed a \emph{phonological} entity, nothing should prevent the computation from manipulating it, as has been proposed by \citet{walker04,łubowicz09:_infix}, although \citet{van_oostendorp_coe} rejects this approach, citing modularity violations.

Resolving this issue is important for the status of modularity in linguistic theory. On the one hand, morpheme\hyp specific effects are a real problem, irrespective of whether they are truly attested or derivable as epiphenomena of other, truly phonological mechanisms. On the other hand, a strictly modular approach that enforces encapsulation and prohibits the mixing of levels appears difficult to reconcile with such effects in a principled way. One potential solution is offered by \citet{bermudez-oterong}, who plausibly suggests that morpheme\hyp specific indices are not to be admitted to the (output of) phonological computation because they are not interpretable by the interface between phonology and phonetics. If they were so interpretable, we would expect them to be somehow reflected in the phonetics (see below \cref{sec:interf-as-interpr} for the preservation of contrasts at the interface): simplifying somewhat, this would mean that, say, in Japanese stretches of segments belonging to Yamato vocabulary could differ from Sino\hyp Japanese stretches in some phonetic parameter. This approach makes the strong prediction that such morpheme\hyp specific phonetic effects should not be a fact of grammar \citep[\emph{pace} work such as that by \eg][]{pierrehumbert02:_word} but rather epiphenomena of a more modular approach\dash specifically a stratal one \citep[\cf also][]{bermudez-otero10:_curren_englis}.

I do not propose a solution to these conundrums in the present thesis; for the sake of the argument, I adhere to a rather strongly modular hypothesis along the lines of \citet{bermudez-oterong}, as it is the more restrictive one in terms of the types of interaction between modules that it allows. In any case resolving these issues requires deep empirical study that is far outside the scope of this particular thesis.

\subsubsection{The rôle of the lexicon}
\label{sec:role-lexicon}

Finally, a word must be said about the rôle of the lexicon. In the classical feed\hyp forward model, the lexicon has a modular status as the endpoint of the derivation, preceding morphosyntax in production and following it in perception. At first blush, this would seem to preclude any access to lexically specific information in the phonology and related modules, putting such a strictly modular approach at odds with recent results in exemplar theory, which have been argued as demonstrating the necessity for phonology to access highly detailed phonetic representations, complete with indexation for all sorts of \enquote{extraphonological}\footnote{Here, \enquote{extraphonological} means \enquote{not influencing prototypically phonological processes such as categorical alternations}.} information \citep{pierrehumbert01:_exemp,pierrehumbert02:_word,scobbie07:_inter}.

However, these extreme views are not the only possible approaches to the lexicon. For instance, in the parallel architecture of \citet{jackendoff97,jackendoff07:_found}, the lexicon does not act as a module on a par with morphosyntax and phonology, but rather mediates between the operation of these modules: lexical activation acts as the link between the activation of different phonological, syntactic, and semantic representations, which themselves are confined to their respective modules. In this type of framework, modularity does not preclude that at least the interface modules should be more weakly encapsulated with respect to non\hyp grammatical types of knowledge, such as knowledge of social networks. For instance, \citet{niedzielski99,hay06:_from,hay10:_stuff} show that the categorization of speech tokens is influenced by the listener's expectations regarding the dialectal origin of the speaker, a result that is completely unexpected under naïve feed\hyp forward models with a universal phonetics\endash phonology interface.

On the other hand, the module that is influenced by social information in these cases is not necessarily \emph{phonology per se}, but rather whatever mechanism effects the mapping from the phonetics to the lexical representation, and lexical recognition as such is known to be driven by all sorts of non\hyp phonological knowledge. In our terms, this is the phonology\hyp phonetics interface, which takes whatever representations the phonetic module operates with and matches them with a phonological string, with input\dash via short- and long\hyp term memory\dash from other components involved in lexical recognition. This allows for both bottom\hyp up mechanisms (\eg the matching of phonetic substance to plausibly related phonological representations) and top\hyp down pressures, such as those related to lexical frequency and extralinguistic (\eg encyclopedic or social) knowledge. It stands to reason that such mechanisms, which implicate overall knowledge of the lexicon (\eg frequency, neighbourhood density etc.) in the interface mappings, enable the existence of less\hyp than\hyp straightforward interactions between the integrative modules. Crucially, however, they require \emph{no} reference to social factors or lexical knowledge \emph{in the phonological computation}. In other words, extralinguistic knowledge may affect the \emph{input} to phonology, but it is not necessarily true that it intrudes on the phonological operations as such.

Once again, a grand theory of extralinguistic knowledge in formal phonology is far beyond the scope of the present thesis. The bottom line for the type of model espoused here is that sound patterns can well be influenced by extralinguistic knowledge, both in an ontogenetic sense and in on\hyp line conditions, but that it is equally possible that phonological computation \emph{per se} remains an encapsulated module with a domain\hyp specific alphabet. This tallies well with approaches such as that of \citet{cohn06:_is,cohn11:_featur}, who suggests that phenomena such as the influence of frequency or prototype effects in perception are powerful, but perhaps not powerful enough to explain the categoricity found in sound patterns cross\hyp linguistically. It follows that a categorical computational element may still arise, which perhaps emerges in some sense from the ambient data, but still possesses its own universe of discourse and its own rules rather than forming one end of a continuum of phenomena with no difference in kind between smaller\hyp scale gradient effects and larger\hyp scale categorical behaviour \citep[à~la][]{wedel}. This argument will arise repeatedly in the following discussion; \cf also \citet{barnesbook,moreton06:_analy,bermudez-diachr,becker11:_surfeit_stimul,beckerng:_asymm_gener_alter_initial_syllab} for related discussion.

Pride of place has been given in this section to the phonetics\endash phonology interface; it is to the relationship between phonetics and phonology that we turn in the next section.

\subsection{Interfacing as interpretation}
\label{sec:interf-as-interpr}

Another issue that arises if interfaces are as complex as integrative modules is the degree of freedom allowed to the interface modules. It is reasonably clear that information can be lost or introduced by the computation in the integrative models: for instance, it is often assumed that morpheme boundaries as such are not part of the phonological output, or that prosodic constituency is largely introduced by the computation (even if some prosodic structure \emph{might} be present in the input).

It is not unthinkable that interface modules could also impoverish the informational content relative to their input. However, I would suggest that such an approach is not restrictive enough, since it essentially obliterates the difference between the integrative phonological module and the interface, allowing for equally powerful transformations in both. Consequently, in this thesis I assume what I will call the Interface Interpretation Principle, formulated as in \ref{iip}.

\ex.\label{iip}\textbf{The Interface Interpretation Principle}\\
An interface module cannot categorically collapse contrasts present in its input

With reference to phonology\endash phonetics interactions, the Interface Interpretation Principle states that all contrasts present in the surface\hyp phonological representation must be available to the phonetics, at least in principle. More specifically, this principle forbids effecting absolute neutralization of phonological contrasts by the interface, ruling out a large class of potential solutions to issues such as absolute neutralization and certain types of opacity.

If neutralization by the interface were permitted, many classic cases of absolute neutralization and opacity in the phonology could be resolved without recourse to a multi\hyp level phonological computation (a major objective of phonological study in the recent past), just by using the feed\hyp forward modular architecture. To take a couple of familiar examples, one could assume that \emph{surface\hyp phonological} representations in Hungarian contain the [$-$low $+$back $-$round] vowels \ipa{[ɯ(ː)]} and \ipa{[ɤ(ː)]}, with the \alternation{[ɯ]}{[i]} and \alternation{[ɤ]}{[e]} contrasts collapsed by the interface. Similarly, a possible analysis of opacity related to the flapping of \ipa{[d]} and \ipa{[t]} in North American English would postulate surface\hyp phonological representations such as \ipa{[ɹəɪtɚ]} for \emph{writer} and \ipa{[ɹaɪdɚ]} for \emph{rider}, with the neutralization of the stops to \ipa{[ɾ]} being part of the interface and the raising process thus transparent in the phonology. Such approaches are prohibited under the Interface Interpretation Principle, since they allow the interface to effect \emph{obligatory} neutralization of contrasts present in the output of the phonology.\footnote{Note that the potential interface\hyp based solutions clearly cannot resolve \emph{all} cases of absolute neutralization or opacity, but only help with those where the absolute neutralization or the opacifying rule come last in the derivation.}

However, I do not propose that categories that are distinct in the phonology will always be mapped to the phonetics in a way that makes them clearly contrastive: quite to the contrary, the phonetics\endash phonology interface \emph{does} allow for situations where tokens belonging to distinct categories are realized in extremely similar ways. The end result is a very high degree of overlap between the permitted ranges of realization of the two categories, as evidence by the existence of incomplete neutralization and near\hyp mergers, which I discuss in the following sections.

\subsubsection{Incomplete neutralization and the window model}
\label{sec:incompl-neutr}

Cases known as \enquote{incomplete neutralization} arise when two (or more, of course) categories are distinct in the phonological output but are realized in extremely similar ways on the surface. Thus, for instance, it has been argued that the process of \enquote{final devoicing} in many languages, normally treated as the neutralization of the laryngeal contrast (as already in \citealp{Tru39}), actually preserves the contrast, since it is recoverable by speakers. Such results have been achieved for final devoicing in Catalan \citep{dinnsen84:_phonol,charles-luce87:_catal}, Polish \citep{slowiaczek85:_polis,slowiaczek89:_percep_polis}, Russian \citep{pye86:_word_russian,dmitrieva10:_phonol}, Dutch \citep{ernestus06:_funct_of_incom_neutr_in_dutch,ernestus07:_intrap_effec_percep_of_voice}, German \citep[\egm][]{port85:_neutr_german}, and Friulian \citep{baroni00:_friul}. Similarly, the North American English flapping process has been argued to represent incomplete neutralization, since the laryngeal feature specification of the coronal stop is recoverable from the length of the preceding vowel (and other cues normally associated with laryngeal contrast), and presumably from vowel quality in dialects with \enquote{Canadian Raising} \citep{fisher76:_inter_englis,fox77:_dental_americ_englis,zue79:_acous_americ_englis,braver11:_incom_americ_englis}.

Incomplete neutralization has been cited in support of both certain approaches to phonological representation \citep[\egm][]{oostendorp08:_incom} and of a complete rejection of formal phonology \citep{port05:_again_formal_phonol}. On the other hand, some of the cases of incomplete neutralization have been criticized as unduly influenced by laboratory conditions, orthography, and similar confounding factors \citep{fourakis84:_german,manaster96,Warner2004251}, and \citet{rooy03:_demys} show that complete neutralization of the laryngeal contrast in word\hyp final position in Afrikaans is progressively more likely as the experimental conditions approach naturalistic settings.\footnote{Also relevant here is \posscite{mihm07:_theor_auslaut_spann_norms_sprac} description of the status of final devoicing in German. He shows that it is a prescriptive norm with a somewhat shaky status in practice, only inconsistently applied even when speaking \enquote{Standard} German, depending on the speaker's dialect background.} Still, \citet{jansen04:_laryn} points out that not all of the experiments reported in the literature are open to criticisms such as those by \citet{fourakis84:_german}.

The modular framework advocated here can accommodate both complete and incomplete neutralization, if the interface between phonetics and phonology is learned and language\hyp specific. Cases of incomplete neutralization arise when the range of variation allowed in the realization of a certain phonological category becomes so large as to overlap the range of realizations permitted by a different phonological category. In other words, the existence of ambiguous tokens does not preclude the existence of distinct categories, but does require an explicit statement of the range of variation permitted by the interface in a particular language in a particular context. A similar approach is envisaged by \citet{scobbie95:_what}, who says: \blockquote[p.~305]{The English words \emph{sip} and \emph{zip} contrast, so surface structure \emph{must} provide feature bundles, say /s/ and /z/, to differentiate them. The /z/ in \emph{buzz} is usually partially devoiced, being prepausal. General (but not necessarily universal) phonetic interpretation rules account for this, so we do not need a feature bundle [\ldots] for \enquote{partly devoiced /z/}.}

This approach can be very naturally paired with the \enquote{window} model of (co)articulation proposed by \citet{keating88,keating90}. She suggests that the phonetics\endash phonology interface determines the phonetic realization of features by assigning to each feature specification a range of values along certain dimensions\dash a window\dash into which the realization of that specification must fall. When the language makes a distinction between two or more featural specifications, the normal situation is that the phonetics\endash phonology interface assigns two non\hyp overlapping windows, ensuring the implementation of this contrast. Formulated in these terms, the Interface Interpretation Principle requires that distinct phonological categories cannot be assigned identical windows in the implementation\dash although it says nothing about the overlap of such windows. Prototypical cases of incomplete neutralization are those where most realizations of one of the categories tend to fall into an area where its window overlaps with the window for the other category, at least along one of the relevant parameters: thus, in a language where devoicing is not yet part of the phonology, we can expect the word\hyp final voiced obstruents to be realized without voicing \emph{most of the time} (with the process possibly being speaker\hyp controlled, \eg in response to social factors), but still retain the possibility of having a voicing realization. Crucially, the converse pattern is not normally allowed in a such a language, \ie phonological voiceless obstruents cannot be realized with voicing,\footnote{Discounting cases of imperfect production: we are interested in controlled aspects of the implementation here.} just as in \posscite{scobbie95:_what} \emph{buzz} example a partially devoiced \ipa{[z]} is allowed in \emph{buzz} but generally not in \emph{bus}.

The approach presented here thus allows for the existence of a number of (incomplete) neutralization patterns, which are given below using final devoicing as an example. Here, as elsewhere in this thesis, I use the notation $\llbracket x\rrbracket$ to refer to the phonetic implementation of the phonological expression $x$, which is itself written as [$x$] when the surface form is at stake (with some caveats to be explicitly made below) and as /$x$/ when the form is not a surface representation.\footnote{The notation is borrowed from semantics, where $\llbracket x\rrbracket$ stands for \enquote{the meaning of $x$}, and reflects the suggestion that the phonetic form is the result of an \emph{interpretation} of the phonological expression in terms of physical events, as enunciated by \citet{pierrehumbert90:_phonol} and in parallel to \posscite{blaho-diss} treatment of the representational system and computational system as the \enquote{syntax of phonology}. In addition, the double\hyp bracket notation is less conspicuous than \posscite[']{hale-reiss2008} \enquote{human\hyp figure} brackets, which are used for what is essentially the same purpose.}

\begin{itemize}
\item No neutralization either in the phonology or the phonetics: \mapping{t \vs d}{t \vs d}{t \vs d}. Attested widely, \eg in English;
\item Neutralization in the phonology: \mapping{t \vs d}{t}{t}. Traditionally assumed to be the most widespread case of neutralization, \eg for German or Russian;
\item Near\hyp neutralization in the interface: \mapping{t \vs d}{t \vs d}{t \vs t/t̬/d̥(/d)}. This is the \enquote{incomplete neutralization} case, characterized by various degrees of overlap between the realizations of the two phonological categories, where the preferences \enquote{inside} one of the classes are driven by several controlled and uncontrolled factors, for instance speech rate, aerodynamic considerations, and possibly social pressures. One relatively clear case in this respect appears to be Afrikaans, where a broader variation in the realization of voiced obstruents is associated with \enquote{experiment\hyp like} conditions, but the allowed range becomes narrower in more natural contexts, presumably due (at least in part) to speech rate effects. (Note, however, that \citealt{rooy03:_demys} draw the opposite conclusion, namely that neutralization is complete, but that speakers disambiguate in more formal settings.)
\end{itemize}

Crucially, the mappings predicted to be impossible are \mapping{t \vs d}{t \vs d}{t} and \mapping{t \vs d}{t \vs d}{t/t̬/d̥/d}, where the contrast is collapsed by the interface, in the sense that all possible realizations are ambiguous with respect to their phonological interpretation. The Interface Interpretation Principle means that if all types of tokens are phonetically ambiguous, in the sense that they can equally well correspond to two underlying phonological categories, then the output of the phonology must also have neutralized the underlying contrast.

From the perspective of a substance\hyp free theory, the most important corollary of this approach is that apparent neutralization can have a number of sources: either phonological neutralization or partial neutralization by the interface. Determining the type of neutralization that a given language exhibits requires either painstaking empirical study, with very careful disentangling of the various phonological, phonetic, and sociolinguistic factors, or evidence from the phonological behaviour of the relevant elements that would show that they are indeed distinct in the phonology. Ideally, of course, the two types of evidence should converge. In \cref{cha:bothoa-breton}, I argue for a particular type of contrast neutralization in Bothoa Breton on the basis of phonological behaviour, and also show that the phonetic implications of the analysis appear to be confirmed by the data.

To conclude, a model of the phonology\endash phonetic interface organized along the lines sketched here is able to deal with incomplete neutralization and also implies a meaningful restriction on the architecture of phonological patterns: contrasts present in the output of phonology cannot be obligatorily neutralized by the phonetics\endash phonology interface.

\subsubsection{Near-mergers and listener-agnostic phonological patterns}
\label{sec:near-merg-list}

One type of pattern where the interface seems to collapse phonological distinctions is the case of the so\hyp called near\hyp mergers. In a near\hyp merger situation, speakers claim to be unaware of a difference in the realization of two distinct categories, but still produce a consistent contrast, which can also be identified in perception experiments \citep{labov72:_quant,labov94:_princ,milroy80:_wheny,di90:_phonat_utah,gordon02:_inves}. In this case, the interface neutralization only seems to affect the perceptual mechanism, and perhaps incompletely at that: although hearers are not conscious of a difference, they are still mostly able to attend to it in commutation tasks, and clearly do not implement a merger in production (as an aside, this type of operation below the level of consciousness is one that is often ascribed to cognitive modules, or \enquote{faculties} as \citealt{fodor83:_modul} calls them).

Near\hyp mergers afford a glimpse into the nature of overlapping windows. As demonstrated especially by \citet{milroy80:_wheny}, near\hyp mergers often involve a significant overlap in the values of their possible realization, \ie a large number of genuinely ambiguous tokens.\footnote{Note, however, that each given category can have additional cues which serve to disambiguate the categories: thus, while formant values show significant overlap or even full merger of the relevant classes in both Belfast English (the \emph{meat\dash mate} merger) and Utah English (the \emph{full\dash fool} merger), the categories can still be disambiguated by the presence of a glide in Belfast \citep{milroy80:_wheny} and by phonation in Utah \citep{di90:_phonat_utah}.} As suggested by \citet{milroy80:_wheny}, it is this large set of ambiguous realizations that leads the speakers to claim the lack of contrast; nevertheless, the range of realization is not \emph{identical}, meaning that the interface again fails to fully neutralize the phonological contrast found on the surface.

The crucial point is, again, that the existence of near\hyp mergers presupposes a clear separation between the cognitive representation in terms of lexically contrastive units (\ie phonology) and the phonetic implementation of these contrasting representations. The fact that some contrasts may appear to be neutralized due to factors such as social pressures does not invalidate the existence of this distinction: the interface always provides at least the \emph{potential} for expressing these contrasts phonetically. Research has shown that such suboptimal contrasts can develop either towards a full merger (which obliterates the contrast at the level of phonology, and eventually of the lexicon) or to a situation where the realizations of the phonological categories drift apart, leading to an apparent \enquote{merger reversal}. The crucial factor here is the preservation of the contrast \emph{in the phonology}, despite the phonetic realizations making it difficult.

A similar argument for the independence of phonological representation and the properties of its phonetic realization can be made on the basis of phonological patterns that persist despite leaving no audible trace. An example is phrase\hyp initial geminate obstruents in Thurgovian German. As described by \citet{kraehenmann01:_swiss_german,kraehenmann03:_quant_aleman}, this language has no laryngeal contrasts, but clearly contrasts long and short (geminate and singleton) consonants (for more on the phonology of Thurgovian German, see below \cref{sec:high-german}). Crucially, the contrast between geminates and singletons is extremely difficult to maintain in non\hyp post\-vocalic contexts. It is thus not surprising that it should be neutralized, for instance, adjacent to another consonant, as \citeauthor{kraehenmann03:_quant_aleman} painstakingly shows. However, the situation is less clear in word\hyp initial position: geminates and singletons clearly contrast following a vowel in a phrasal context, but at the acoustic level there is no way of distinguishing the two classes in absolute phrase\hyp initial position \citep{kraehenmann03:_quant_aleman}. Nevertheless, as \citet{kraehenmann08:_durat_swiss_german} demonstrate, Thurgovian German speakers do make a distinction in closure duration in this position, even though it is vacuous acoustically.

This case shows that speakers do not just pick up output generalizations, since there is no possibility for them to learn that there are two classes for phrase\hyp initial stops: rather, they must make an abstract generalization, tying the two classes of stops in phrase\hyp medial position to the two phrase\hyp initial classes of stops, which is presumably done by setting up an abstract representation of the lexical item which includes the geminate\fshyp singleton distinction. Again, phonological representation cannot be simply identified with the phonetic form, but rather requires
abstraction.

\subsection{Conclusion on interfaces}
\label{sec:concl-interf}

In this section I have argued that the phonetics\endash phonology interface is best viewed not as a transducer effecting a highly deterministic mapping between phonological and phonetic representation, but rather as something akin to a module translating phonological representations into phonetic ones (and vice versa). Such a view of the interface is necessary to uphold the autonomy of phonological representation and computation, since a transducer along the lines of \citet{hale-kissock-reiss,hale-reiss2008} cannot account for the range of variation found in the realization of phonological phenomena.

I have argued that this view of the interface makes some types of interaction between the components of grammar (such as morphologically conditioned phonetics) an architectural impossibility, although the rôle of the lexicon remains an open question. I have also suggested that a boundary condition on the operation of the phonetics\endash phonology interface is the impossibility to enforce obligatory neutralization of phonological contrasts (although accidental neutralization, \ie category overlap, is allowed) and to introduce obligatory contrasts not present in the phonology. As we shall see throughout this thesis, these conditions are a useful heuristic to separate truly phonological patterns from interface mappings.

\section{The (non-)importance of overgeneralization}
\label{sec:non--importance}

An important argument against substance\hyp free phonology is that it appears to overgenerate possible grammars, \ie that the set of grammars deemed possible within this framework is substantially larger than the set of grammars that are attested. I deal with two possible version of this argument: one which I call the \enquote{crazy\hyp pattern} issue and one that I call the \enquote{frequency reproduction} question.

\subsection{The \enquote{crazy\hyp pattern} issue}
\label{sec:enqu-patt-issue}

With an essentially arbitrary mapping between phonetics and phonology and no grounding conditions on this interface, substance\hyp free phonology appears open to the criticism of being unable to distinguish between languages that are attested, or at least attestable, and languages that are predicted to be computationally possible but are not attested, and felt highly unlikely to be attested, because the process is deemed to be \enquote{unintuitive} or \enquote{unlearnable}.

This argument has been rebutted in previous literature \citep{hale-kissock-reiss,reiss07:_modul,hale-reiss2008,blaho-diss}, so I will not rehash the argumentation at length. The counter\hyp arguments fall into three main groups: accidents of history, diachrony, and learnability.

\subsubsection{Accidents of history}
\label{sec:accidents-history}

This is the most obvious argument: the set of attested languages is to an extremely large degree shaped by externalities such as the exigencies of population movements, language extinction, the availability of fieldworkers in a certain time and place, and so on. Apart from the obviously accidental nature of the set of \enquote{attested} phenomena (which, it must be pointed out, will also tend to seep into phonologists' intuitions of what a \enquote{possible} pattern looks like), there are two further considerations.

First, as \citet{hale-kissock-reiss} point out, the extinction of language also takes out all its hypothetical descendants from the set of \enquote{attestable} languages, which means that many \enquote{computable} languages (\ie those that should be declared possible by the grammar) are not attested for reasons that have nothing to do with the properties of computation.

Second, research in sociolinguistics and typology has shown that small speaker communities tend to preserve typologically unusual structures, including those which functionally based frameworks would treat as dispreferred, much better than large communities \citep{nettle99:_is,nettle99:_using_social_impac_theor,trudgill10:_inves,trudgill11:_sociol,wohlgemuth10:_languag}. Given the high rate of extinction of languages with small community size, both in the very recent past and, presumably, in connection with events such as the rapid expansion of agriculture, it is highly likely that \enquote{unusual} patterns were disproportionately represented among those that happen to be unattested in research in theoretical linguistics. It would then be highly premature to make any pronouncements on whether a given pattern is impossible \emph{in principle}. Several cautionary tales are provided by the history of metrical typology, where the existence of phenomena such as ternary rhythm \citep{curt-diss}, initial extrametricality \citep{buckley92:_theor_kashay}, and quantity\hyp insensitive iambs \citep{altshuler09:_quant_insen_iambs_osage} was at some point doubted or denied (and occasionally accounted for theoretically).

\subsubsection{Diachrony}
\label{sec:diachrony-1}

This is the most widely recognized filter. Given the fact that phonological change is not random but clearly driven by both the state of the ambient data and the functional and formal biases operative in production, perception, and acquisition, it is only to be expected that some types of sound change should be much more frequent than others, and also that the grammars favoured by these biases will be overrepresented cross\hyp linguistically. As emphasized by \citet{blevins}, the synchronic grammar does not need to encode these preferences; \cf also \citet{kavitskaya02:_compen,barnesbook,reiss07:_modul}. On the other hand, the same mechanism of diachronic change can produce \enquote{unintuitive} or functionally unmotivated patterns, as argued especially by \citet{mielke-diss,yu07}. The (un)likelihood of the appearance of such patterns is a function of the low probability of the changes that lead to them, and, again, should not be a fact of synchronic grammar (see also \cref{sec:frequency-occurrence} below).

\subsubsection{Learnability}
\label{sec:learnability}

Finally, as argued by \citet{reiss07:_modul}, some patterns are predicted to be possible under a certain permutation of representational and\fshyp or computational prerequisites but unlearnable under some independently required assumptions, for instance because the acquisition system is set up in a way that the learner always acquires a different grammar from the set of data produced by the \enquote{implausible} one.  Since the task of the theory of grammar is to account for the possibilities of the human computational system, it is not necessary to exclude such computable but unlearnable languages from the grammar. For concrete implementation of similar ideas, see \citet{Alderete20081177} and, with less bias towards OT, \citet{Heinz-2009-RLLSP}.

\subsection{Frequency of occurrence}
\label{sec:frequency-occurrence}

In connection to the overgeneration argument it must be noted that non\hyp attestation of some pattern is merely a special case of attestation with extremely low frequency. In substance\hyp free phonology, there is an important difference between \enquote{accidental non\hyp attestation}, \ie an accidental gap, and \enquote{principled non\hyp attestation}, \ie a pattern that cannot be generated by the grammar. On the other hand, there are no commitments from the grammar to model the frequency of the occurrence of some pattern either within a language (synchronic variation) or cross\hyp linguistically.

In much of the OT literature, treating unattested patterns as accidental gaps seems to be frowned upon, since the ultimate aim is to achieve a tight fit between the set of attested phenomena and the set of mappings allowed by the grammar. This is the factorial\hyp typology criticism: a grammar comprising constraints that will, under some ranking, give some result deemed to be undesirable, is considered inferior to a grammar that manages to exclude that result using harmonic bounding.

Another criticism relies on the fact that factorial typology predicts not just the set of attested languages but also their expected frequency: given that multiple rankings can lead to a single input\dash output mapping, then, \emph{ceteris paribus}, it is expected that grammars favoured by more rankings should be more frequent cross\hyp linguistically, providing an additional restriction on choosing the \enquote{correct grammar}.

However, all these criticisms suffer from a major problem, in that they are more or less implicitly based on the assumption that the distribution of constraint rankings is random. This assumption is necessary for arguments such as \enquote{if grammar $G$ were the correct grammar, we would expect there to be a language $L$ that exhibits undesirable property $P$; such languages are unattested, therefore $G$ is not to be preferred if alternatives excluding $P$ are available}. This argument suffers not just from assuming impossibility based on lack of attestation, but from treating all conceivable rankings as having approximately equal probabilities: otherwise, it is not at all clear why we \enquote{should expect} $L$ to exist.

Given that language is learned from ambient data, we expect the distribution of attested rankings to be significantly skewed in the direction of rankings that are similar to those attested in synchronic systems at any given time, and the distribution of those, as discussed above in \cref{sec:enqu-patt-issue}, is far from random. In this situation, it is not at all obvious that we ever \enquote{expect} some unusual pattern to be attested: it may be accidentally unattested due to language extinction, or simply the lack of a description, or it may represent a pattern that can lead the learner to converge on a different grammar, or it may only arise as the result of a chain of highly unlikely diachronic changes. None of these cases require building an explanation for the lack of the pattern into the formal mechanism of the grammar.

A final question in this connection is whether it is the task of the theoretical linguist to account for the cross\hyp linguistic frequency of certain patterns. Arguably, this frequency is not an aspect of the human knowledge of language, but rather an epiphenomenon of the diachronic changes and the biases active in language use and acquisition. The theoretical linguist does not study behaviour as such, but uses it as a window on knowledge of language, in order to find out whether a certain pattern is possible or not. Typological frequency is not part of that knowledge, and therefore lies outside the remit of grammar; for more discussion on this point, see \citet{newmeyer05:_possib,harris08,harris10:_explain}. It is thus not a problem for substance\hyp free phonology that it does worse than orthodox approaches at accounting for the precise quantitative characteristics of cross\hyp linguistic variation, because, as a theory of phonology, it is not supposed to.

\subsection{Is \enquote{Universal Grammar} relevant for phonology?}
\label{sec:enqu-gramm-relev}

The rejection of straightforwardly typological approaches argued for here does not make substance\hyp free phonology unfalsifiable; rather, it represents a difference of approaches to what the remit of \enquote{Universal Grammar} should be. Substance\hyp free phonology does predict that certain types of phonological patterns (understood as input\endash output mappings effected by the phonological module). However, extracting the relevant generalizations is not at all straightforward. Whatever universals exist in phonology, they are, in \posscite{hyman08:_univer} terms, analytic rather than absolute. Since the sources of variation in sound patterns are numerous in almost any theoretical approach (except the most expansionist ones), \enquote{[i]t is misguided to attribute every accidentally true statement about human language to U[niversal] G[rammar]} \citep[p.~461]{odden88:_anti_ocp}.

In other words, any pronouncements on what the phonological component should and should not be allowed to do require a precise statement of the pattern in terms of a particular theory, rather than inspecting some data which might or might not be truly phonological; similar sentiments are expressed by \citet{nevins09} in his reaction to \posscite{evans09} rejection of abstract analysis (\cf also the response by \citealp{harbour09}) and by \citet{reiss03:_quant,hale-reiss2008}.  Since phonological theory has nothing to say about issues such as the interaction of particular features, as opposed to stating general conditions on the types of featural interaction, it \enquote{overgenerates} the set of conceivable descriptive patterns. However, since the descriptive patterns are contingent not just on the phonological computation but also on the factors described above, such as phonetics\endash phonology mappings or historical accidents, the minimalist phonological computations such as those shown here and more substance\hyp found analyses common in the literature are not directly comparable. Rather, conventional grammars with an expansionist rôle for phonology should be compared to comprehensive theories covering all of the factors behind the attestation of surface patterns, and traditional factorial typology is clearly only a part of this enterprise.

As discussed below in \cref{sec:power-computation}, representational issues play a central rôle in identifying the precise predictions of a phonological framework, because the computational complexity of the resulting set of predicted languages hinges on representations to at least the same degree as it does on the choice of the computational framework \citep{Heinz-2011-CPGLF,heinz11:_tier_stric_local_const_phonol}. While I do recognize that overgeneration is a valid concern for a theory of grammar, I suggest that arguments based on overgeneration and computational complexity are somewhat premature before a fully explicit and (at least) descriptively adequate representational framework has been developed. Consequently, in this thesis I concentrate on representational aspects of the theory of substance\hyp free phonology.

\section{Summary}
\label{sec:summary}

In this chapter I presented some very general outlines of the research programme behind the present thesis. I have argued that there are several important consequences to the idea of phonology as a separate module. In particular, phonology is \emph{autonomous}, which means first and foremost that there exist a domain\hyp specific representational system and a domain\hyp specific type of computation. Several corollaries follow from this idea, of which the following are of greatest importance in the context of this thesis:

\begin{itemize}
\item The autonomy of phonological representations: phonological representations are always language\hyp specific, cannot be unambiguously recovered from the signal, and are built on the basis of language\hyp internal evidence rather than aprioristic assumptions about the phonology\endash phonetics mapping;
\item The autonomy of phonological computation: the principles of phonological computation make no reference to functional grounding, but are domain\hyp specific. The fact that typological distributions closely follow functional bases is not an \emph{explanandum} for a theory of phonological computation, but follows from considerations related to language acquisition and language change;
\item The complexity of interfaces: interfaces effect the translation between different domains in complex ways, as relatively autonomous modules rather than deterministic transducers. However, there are some conditions on the functioning of the interfaces: in particular, they cannot collapse or introduce arbitrary contrasts present in the input.
\end{itemize}

In the next two chapters I make some concrete proposals with respect to computation and representation that will be used to analyse a range of specific sound patterns in \cref{part:analysis}.
